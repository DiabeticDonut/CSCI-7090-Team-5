
@article{van_der_schyff_privacy_2024,
	title = {Privacy policy analysis: A scoping review and research agenda},
	volume = {146},
	issn = {01674048},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404824003705},
	doi = {10.1016/j.cose.2024.104065},
	shorttitle = {Privacy policy analysis},
	abstract = {Online users often neglect the importance of privacy policies - a critical aspect of digital privacy and data protection. This scoping review addresses this oversight by delving into privacy policy analysis, aiming to establish a comprehensive research agenda. The study’s objective was to explore the analytic techniques employed in privacy policy analysis and to identify the associated challenges. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses for Scoping Reviews ({PRISMA}-{ScR}) checklist, the review selected n = 97 relevant studies. The findings reveal a diverse array of techniques used, encompassing automated machine learning and natural language processing, and manual content analysis. Notably, researchers grapple with challenges like linguistic nuances, ambiguity, and complex data harvesting methods. Additionally, the lack of privacy-centric theoretical frameworks and a dearth of user evaluations in many studies limit their real-world applicability. The review concludes by proposing a set of research recommendations to shape the future research agenda in privacy policy analysis.},
	pages = {104065},
	journaltitle = {Computers \& Security},
	shortjournal = {Computers \& Security},
	author = {Van Der Schyff, Karl and Prior, Suzanne and Renaud, Karen},
	urldate = {2025-02-11},
	date = {2024-11},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\2UGQGG54\\Van Der Schyff et al. - 2024 - Privacy policy analysis A scoping review and research agenda.pdf:application/pdf},
}

@article{mhaidli_researchers_2023,
	title = {Researchers’ Experiences in Analyzing Privacy Policies: Challenges and Opportunities},
	volume = {2023},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2299-0984},
	url = {https://petsymposium.org/popets/2023/popets-2023-0111.php},
	doi = {10.56553/popets-2023-0111},
	shorttitle = {Researchers’ Experiences in Analyzing Privacy Policies},
	abstract = {Companies’ privacy policies and their contents are being analyzed for many reasons, including to assess the readability, usability, and utility of privacy policies; to extract and analyze data practices of apps and websites; to assess compliance of companies with relevant laws and their own privacy policies, and to develop tools and machine learning models to summarize and read policies. Despite the importance and interest in studying privacy policies from researchers, regulators, and privacy activists, few best practices or approaches have emerged and infrastructure and tool support is scarce or scattered. In order to provide insight into how researchers study privacy policies and the challenges they face when doing so, we conducted 26 interviews with researchers from various disciplines who have conducted research on privacy policies. We provide insights on a range of challenges around policy selection, policy retrieval, and policy content analysis, as well as multiple overarching challenges researchers experienced across the research process. Based on our findings, we discuss opportunities to better facilitate privacy policy research, including research directions for methodologically advancing privacy policy analysis, potential structural changes around privacy policies, and avenues for fostering an interdisciplinary research community and maturing the field.},
	pages = {287--305},
	number = {4},
	journaltitle = {Proceedings on Privacy Enhancing Technologies},
	shortjournal = {{PoPETs}},
	author = {Mhaidli, Abraham and Fidan, Selin and Doan, An and Herakovic, Gina and Srinath, Mukund and Matheson, Lee and Wilson, Shomir and Schaub, Florian},
	urldate = {2025-02-14},
	date = {2023-10},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\Z925XBA3\\Mhaidli et al. - 2023 - Researchers’ Experiences in Analyzing Privacy Policies Challenges and Opportunities.pdf:application/pdf},
}

@article{javed_systematic_2025,
	title = {A Systematic Review of Privacy Policy Literature},
	volume = {57},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3698393},
	doi = {10.1145/3698393},
	abstract = {An organization’s privacy policy states how it collects, stores, processes, and shares its users’ personal information. The growing number of data protection laws and regulations, as well as the numerous sectors where the organizations are collecting user information, has led to the investigation of privacy policies with regards to their accessibility, readability, completeness, comparison with organization’s actual data practices, use of machine learning/natural language processing for automated analysis, and comprehension/perception/concerns of end-users via summarization/visualization tools and user studies. However, there is limited work on systematically reviewing the existing research on this topic. We address this gap by conducting a systematic review of the existing privacy policy literature. To this end, we compiled and analyzed 202 papers (published till 31st December, 2023) that investigated privacy policies. Our work advances the field of privacy policies by summarizing the analysis techniques that have been used to study them, the data protection laws/regulations explored, and the sectors to which these policies pertain. We provide actionable insights for organizations to achieve better end-user privacy.},
	pages = {1--43},
	number = {2},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Javed, Yousra and Sajid, Ayesha},
	urldate = {2025-02-14},
	date = {2025-02-28},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\76PJWQSM\\Javed and Sajid - 2025 - A Systematic Review of Privacy Policy Literature.pdf:application/pdf},
}

@article{bardus_data_2022,
	title = {Data Management and Privacy Policy of {COVID}-19 Contact-Tracing Apps: Systematic Review and Content Analysis},
	volume = {10},
	rights = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in {JMIR} {mHealth} and {uHealth}...") is properly cited with original {URL} and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.},
	url = {https://mhealth.jmir.org/2022/7/e35195},
	doi = {10.2196/35195},
	shorttitle = {Data Management and Privacy Policy of {COVID}-19 Contact-Tracing Apps},
	abstract = {Background: {COVID}-19 digital contact-tracing apps were created to assist public health authorities in curbing the pandemic. These apps require users’ permission to access specific functions on their mobile phones, such as geolocation, Bluetooth or Wi-Fi connections, or personal data, to work correctly. As these functions have privacy repercussions, it is essential to establish how contact-tracing apps respect users’ privacy.
Objective: This study aimed to systematically map existing contact-tracing apps and evaluate the permissions required and their privacy policies. Specifically, we evaluated the type of permissions, the privacy policies’ readability, and the information included in them.
Methods: We used custom Google searches and existing lists of contact-tracing apps to identify potentially eligible apps between May 2020 and November 2021. We included contact-tracing or exposure notification apps with a Google Play webpage from which we extracted app characteristics (eg, sponsor, number of installs, and ratings). We used Exodus Privacy to systematically extract the number of permissions and classify them as dangerous or normal. We computed a Permission Accumulated Risk Score representing the threat level to the user’s privacy. We assessed the privacy policies’ readability and evaluated their content using a 13-item checklist, which generated a Privacy Transparency Index. We explored the relationships between app characteristics, Permission Accumulated Risk Score, and Privacy Transparency Index using correlations, chi-square tests, or {ANOVAs}.
Results: We identified 180 contact-tracing apps across 152 countries, states, or territories. We included 85.6\% (154/180) of apps with a working Google Play page, most of which (132/154, 85.7\%) had a privacy policy document. Most apps were developed by governments (116/154, 75.3\%) and totaled 264.5 million installs. The average rating on Google Play was 3.5 ({SD} 0.7). Across the 154 apps, we identified 94 unique permissions, 18\% (17/94) of which were dangerous, and 30 trackers. The average Permission Accumulated Risk Score was 22.7 ({SD} 17.7; range 4-74, median 16) and the average Privacy Transparency Index was 55.8 ({SD} 21.7; range 5-95, median 55). Overall, the privacy documents were difficult to read (median grade level 12, range 7-23); 67\% (88/132) of these mentioned that the apps collected personal identifiers. The Permission Accumulated Risk Score was negatively associated with the average App Store ratings (r=−0.20; P=.03; 120/154, 77.9\%) and Privacy Transparency Index (r=−0.25; P\&lt;.001; 132/154, 85.7\%), suggesting that the higher the risk to one’s data, the lower the apps’ ratings and transparency index.
Conclusions: Many contact-tracing apps were developed covering most of the planet but with a relatively low number of installs. Privacy-preserving apps scored high in transparency and App Store ratings, suggesting that some users appreciate these apps. Nevertheless, privacy policy documents were difficult to read for an average audience. Therefore, we recommend following privacy-preserving and transparency principles to improve contact-tracing uptake while making privacy documents more readable for a wider public.},
	pages = {e35195},
	number = {7},
	journaltitle = {{JMIR} {mHealth} and {uHealth}},
	author = {Bardus, Marco and Daccache, Melodie Al and Maalouf, Noel and Sarih, Rayan Al and Elhajj, Imad H.},
	urldate = {2025-02-14},
	date = {2022-07-12},
	note = {Company: {JMIR} {mHealth} and {uHealth}
Distributor: {JMIR} {mHealth} and {uHealth}
Institution: {JMIR} {mHealth} and {uHealth}
Label: {JMIR} {mHealth} and {uHealth}
Publisher: {JMIR} Publications Inc., Toronto, Canada},
	file = {Full Text:C\:\\Users\\devam\\Zotero\\storage\\LJYVS47F\\Bardus et al. - 2022 - Data Management and Privacy Policy of COVID-19 Contact-Tracing Apps Systematic Review and Content A.pdf:application/pdf;Snapshot:C\:\\Users\\devam\\Zotero\\storage\\7WW5AT83\\e35195.html:text/html},
}

@article{del_alamo_systematic_2022,
	title = {A systematic mapping study on automated analysis of privacy policies},
	volume = {104},
	issn = {0010-485X, 1436-5057},
	url = {https://link.springer.com/10.1007/s00607-022-01076-3},
	doi = {10.1007/s00607-022-01076-3},
	abstract = {A privacy policy describes the operations an organization carries out on its users’ personal data and how it applies data protection principles. The automated analysis of privacy policies is a multidisciplinary research topic producing a growing but scattered body of knowledge. We address this gap by conducting a systematic mapping study which provides an overview of the ﬁeld, identiﬁes research opportunities, and suggests future research lines. Our study analyzed 39 papers from the 1097 publications found on the topic, to ﬁnd what information can be automatically extracted from policies presented as textual documents, what this information is applied to, and what analysis techniques are being used. We observe that the techniques found can identify individual pieces of information from the policies with good results. However, further advances are needed to put them in context and provide valuable insight to end-users, organizations dealing with data protection laws and data protection authorities.},
	pages = {2053--2076},
	number = {9},
	journaltitle = {Computing},
	shortjournal = {Computing},
	author = {Del Alamo, Jose M. and Guaman, Danny S. and García, Boni and Diez, Ana},
	urldate = {2025-02-15},
	date = {2022-09},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\HKJRT7IQ\\Del Alamo et al. - 2022 - A systematic mapping study on automated analysis of privacy policies.pdf:application/pdf},
}

@article{benjumea_privacy_2020,
	title = {Privacy Assessment in Mobile Health Apps: Scoping Review},
	volume = {8},
	issn = {2291-5222},
	url = {https://mhealth.jmir.org/2020/7/e18868},
	doi = {10.2196/18868},
	shorttitle = {Privacy Assessment in Mobile Health Apps},
	abstract = {Background: Privacy has always been a concern, especially in the health domain. The proliferation of mobile health ({mHealth}) apps has led to a large amount of sensitive data being generated. Some authors have performed privacy assessments of {mHealth} apps. They have evaluated diverse privacy components; however, different authors have used different criteria for their assessments.
Objective: This scoping review aims to understand how privacy is assessed for {mHealth} apps, focusing on the components, scales, criteria, and scoring methods used. A simple taxonomy to categorize the privacy assessments of {mHealth} apps based on component evaluation is also proposed.
Methods: We followed the methodology defined by Arksey and O’Malley to conduct a scoping review. Included studies were categorized based on the privacy component, which was assessed using the proposed taxonomy.
Results: The database searches retrieved a total of 710 citations—24 of them met the defined selection criteria, and data were extracted from them. Even though the inclusion criteria considered articles published since 2009, all the studies that were ultimately included were published from 2014 onward. Although 12 papers out of 24 (50\%) analyzed only privacy, 8 (33\%) analyzed both privacy and security. Moreover, 4 papers (17\%) analyzed full apps, with privacy being just part of the assessment. The evaluation criteria used by authors were heterogeneous and were based on their experience, the literature, and/or existing legal frameworks. Regarding the set of items used for the assessments, each article defined a different one. Items included app permissions, analysis of the destination, analysis of the content of communications, study of the privacy policy, use of remote storage, and existence of a password to access the app, among many others. Most of the included studies provided a scoring method that enables the comparison of privacy among apps.
Conclusions: The privacy assessment of {mHealth} apps is a complex task, as the criteria used by different authors for their evaluations are very heterogeneous. Although some studies about privacy assessment have been conducted, a very large set of items to evaluate privacy has been used up until now. In-app information and privacy policies are primarily utilized by the scientific community to extract privacy information from {mHealth} apps. The creation of a scale based on more objective criteria is a desirable step forward for privacy assessment in the future.},
	pages = {e18868},
	number = {7},
	journaltitle = {{JMIR} {mHealth} and {uHealth}},
	shortjournal = {{JMIR} Mhealth Uhealth},
	author = {Benjumea, Jaime and Ropero, Jorge and Rivera-Romero, Octavio and Dorronzoro-Zubiete, Enrique and Carrasco, Alejandro},
	urldate = {2025-02-15},
	date = {2020-07-02},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\LIJ3KAR4\\Benjumea et al. - 2020 - Privacy Assessment in Mobile Health Apps Scoping Review.pdf:application/pdf},
}

@misc{tang_policygpt_2023,
	title = {{PolicyGPT}: Automated Analysis of Privacy Policies with Large Language Models},
	url = {http://arxiv.org/abs/2309.10238},
	doi = {10.48550/arXiv.2309.10238},
	shorttitle = {{PolicyGPT}},
	abstract = {Privacy policies serve as the primary conduit through which online service providers inform users about their data collection and usage procedures. However, in a bid to be comprehensive and mitigate legal risks, these policy documents are often quite verbose. In practical use, users tend to click the Agree button directly rather than reading them carefully. This practice exposes users to risks of privacy leakage and legal issues. Recently, the advent of Large Language Models ({LLM}) such as {ChatGPT} and {GPT}-4 has opened new possibilities for text analysis, especially for lengthy documents like privacy policies. In this study, we investigate a privacy policy text analysis framework {PolicyGPT} based on the {LLM}. This framework was tested using two datasets. The first dataset comprises of privacy policies from 115 websites, which were meticulously annotated by legal experts, categorizing each segment into one of 10 classes. The second dataset consists of privacy policies from 304 popular mobile applications, with each sentence manually annotated and classified into one of another 10 categories. Under zero-shot learning conditions, {PolicyGPT} demonstrated robust performance. For the first dataset, it achieved an accuracy rate of 97\%, while for the second dataset, it attained an 87\% accuracy rate, surpassing that of the baseline machine learning and neural network models.},
	number = {{arXiv}:2309.10238},
	publisher = {{arXiv}},
	author = {Tang, Chenhao and Liu, Zhengliang and Ma, Chong and Wu, Zihao and Li, Yiwei and Liu, Wei and Zhu, Dajiang and Li, Quanzheng and Li, Xiang and Liu, Tianming and Fan, Lei},
	urldate = {2025-02-17},
	date = {2023-09-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2309.10238 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\3Q6PPB8V\\Tang et al. - 2023 - PolicyGPT Automated Analysis of Privacy Policies with Large Language Models.pdf:application/pdf},
}

@inproceedings{farooq_privacy_2020,
	location = {Lahore, Pakistan},
	title = {Privacy Policies' Readability Analysis of Contemporary Free Healthcare Apps},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-7281-9050-1},
	url = {https://ieeexplore.ieee.org/document/9332991/},
	doi = {10.1109/ICOSST51357.2020.9332991},
	eventtitle = {2020 14th International Conference on Open Source Systems and Technologies ({ICOSST})},
	pages = {1--7},
	booktitle = {2020 14th International Conference on Open Source Systems and Technologies ({ICOSST})},
	publisher = {{IEEE}},
	author = {Farooq, Emmen and Nawaz Ui Ghani, M. Ahmad and Naseer, Zuhaib and Iqbal, Shaukat},
	urldate = {2025-02-18},
	date = {2020-12-16},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\UU7ANFSD\\Farooq et al. - 2020 - Privacy Policies' Readability Analysis of Contemporary Free Healthcare Apps.pdf:application/pdf},
}

@inproceedings{adhikari_privacy_2022,
	title = {Privacy Policy Analysis with Sentence Classification},
	url = {https://ieeexplore.ieee.org/abstract/document/9851977},
	doi = {10.1109/PST55820.2022.9851977},
	abstract = {Privacy policies inform users of the data practices and access protocols employed by organizations and their digital counterparts. Research has shown that users often feel that these privacy policies are lengthy and complex to read and comprehend. However, it is critical for people to be aware of the data access practices employed by the organizations. Hence, much research has focused on automatically extracting privacy-specific artifacts from the policies, predominantly by using natural language classification tools. However, these classification tools are designed primarily for the classification of paragraphs or segments of the policies. In this paper, we report on our research where we identify the gap in classifying policies at a segment level, and provide an alternate definition of segment classification using sentence classification. To this aid, we train and evaluate sentence classifiers for privacy policies using {BERT} and {XLNet}. Our approach demonstrates improvements in prediction quality of existing models and hence, surpasses the current baselines for classification models, without requiring additional parameter and model tuning. Using our sentence classifiers, we also study topical structures in Alexa top 5000 website policies, in order to identify and quantify the diffusion of information pertaining to privacy-specific topics in a policy.},
	eventtitle = {2022 19th Annual International Conference on Privacy, Security \& Trust ({PST})},
	pages = {1--10},
	booktitle = {2022 19th Annual International Conference on Privacy, Security \& Trust ({PST})},
	author = {Adhikari, Andrick and Das, Sanchari and Dewri, Rinku},
	urldate = {2025-02-19},
	date = {2022-08},
	keywords = {Access protocols, Automated Classification, Bit error rate, Data privacy, Natural languages, {NLP}, Organizations, Privacy, Privacy Policy, Usable Privacy and Security, Virtual assistants},
	file = {Full Text PDF:C\:\\Users\\devam\\Zotero\\storage\\7QI67HSY\\Adhikari et al. - 2022 - Privacy Policy Analysis with Sentence Classification.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\devam\\Zotero\\storage\\IN4Q9XML\\9851977.html:text/html},
}

@misc{rodriguez_large_2024,
	title = {Large Language Models: A New Approach for Privacy Policy Analysis at Scale},
	url = {http://arxiv.org/abs/2405.20900},
	doi = {10.48550/arXiv.2405.20900},
	shorttitle = {Large Language Models},
	abstract = {The number and dynamic nature of web and mobile applications presents significant challenges for assessing their compliance with data protection laws. In this context, symbolic and statistical Natural Language Processing ({NLP}) techniques have been employed for the automated analysis of these systems' privacy policies. However, these techniques typically require labor-intensive and potentially error-prone manually annotated datasets for training and validation. This research proposes the application of Large Language Models ({LLMs}) as an alternative for effectively and efficiently extracting privacy practices from privacy policies at scale. Particularly, we leverage well-known {LLMs} such as {ChatGPT} and Llama 2, and offer guidance on the optimal design of prompts, parameters, and models, incorporating advanced strategies such as few-shot learning. We further illustrate its capability to detect detailed and varied privacy practices accurately. Using several renowned datasets in the domain as a benchmark, our evaluation validates its exceptional performance, achieving an F1 score exceeding 93\%. Besides, it does so with reduced costs, faster processing times, and fewer technical knowledge requirements. Consequently, we advocate for {LLM}-based solutions as a sound alternative to traditional {NLP} techniques for the automated analysis of privacy policies at scale.},
	number = {{arXiv}:2405.20900},
	publisher = {{arXiv}},
	author = {Rodriguez, David and Yang, Ian and Alamo, Jose M. Del and Sadeh, Norman},
	urldate = {2025-02-19},
	date = {2024-05-31},
	eprinttype = {arxiv},
	eprint = {2405.20900 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
	file = {Preprint PDF:C\:\\Users\\devam\\Zotero\\storage\\G2U6DM8L\\Rodriguez et al. - 2024 - Large Language Models A New Approach for Privacy Policy Analysis at Scale.pdf:application/pdf;Snapshot:C\:\\Users\\devam\\Zotero\\storage\\KUU53832\\2405.html:text/html},
}

@article{andow_policylint_nodate,
	title = {{PolicyLint}: Investigating Internal Privacy Policy Contradictions on Google Play},
	abstract = {Privacy policies are the primary mechanism by which companies inform users about data collection and sharing practices. To help users better understand these long and complex legal documents, recent research has proposed tools that summarize collection and sharing. However, these tools have a signiﬁcant oversight: they do not account for contradictions that may occur within an individual policy. In this paper, we present {PolicyLint}, a privacy policy analysis tool that identiﬁes such contradictions by simultaneously considering negation and varying semantic levels of data objects and entities. To do so, {PolicyLint} automatically generates ontologies from a large corpus of privacy policies and uses sentence-level natural language processing to capture both positive and negative statements of data collection and sharing. We use {PolicyLint} to analyze the policies of 11,430 apps and ﬁnd that 14.2\% of these policies contain contradictions that may be indicative of misleading statements. We manually verify 510 contradictions, identifying concerning trends that include the use of misleading presentation, attempted redeﬁnition of common understandings of terms, conﬂicts in regulatory deﬁnitions (e.g., {US} and {EU}), and “laundering” of tracking information facilitated by sharing or collecting data that can be used to derive sensitive information. In doing so, {PolicyLint} signiﬁcantly advances automated analysis of privacy policies.},
	author = {Andow, Benjamin and Mahmud, Samin Yaseer},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\QK4DY9KH\\Andow and Mahmud - PolicyLint Investigating Internal Privacy Policy Contradictions on Google Play.pdf:application/pdf},
}

@article{cui_poligraph_nodate,
	title = {{PoliGraPh}: Automated Privacy Policy Analysis using Knowledge Graphs},
	abstract = {Privacy policies disclose how an organization collects and handles personal information. Recent work has made progress in leveraging natural language processing ({NLP}) to automate privacy policy analysis and extract data collection statements from different sentences, considered in isolation from each other. In this paper, we view and analyze, for the first time, the entire text of a privacy policy in an integrated way. In terms of methodology: (1) we define {POLIGRAPH}, a type of knowledge graph that captures statements in a privacy policy as relations between different parts of the text; and (2) we develop an {NLP}-based tool, {POLIGRAPH}-{ER}, to automatically extract {POLIGRAPH} from the text. In addition, (3) we revisit the notion of ontologies, previously defined in heuristic ways, to capture subsumption relations between terms. We make a clear distinction between local and global ontologies to capture the context of individual privacy policies, application domains, and privacy laws. Using a public dataset for evaluation, we show that {POLIGRAPH}-{ER} identifies 40\% more collection statements than prior state-of-the-art, with 97\% precision. In terms of applications, {POLIGRAPH} enables automated analysis of a corpus of privacy policies and allows us to: (1) reveal common patterns in the texts across different privacy policies, and (2) assess the correctness of the terms as defined within a privacy policy. We also apply {POLIGRAPH} to: (3) detect contradictions in a privacy policy, where we show false alarms by prior work, and (4) analyze the consistency of privacy policies and network traffic, where we identify significantly more clear disclosures than prior work.},
	author = {Cui, Hao and Trimananda, Rahmadi and Markopoulou, Athina and Jordan, Scott},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\LFAP43CJ\\Cui et al. - PoliGraPh Automated Privacy Policy Analysis using Knowledge Graphs.pdf:application/pdf},
}

@article{hakiem_security_2024,
	title = {Security and Privacy Policy Assessment in Mobile Health Applications: A Literature Review},
	volume = {14},
	issn = {18166075, 18180523},
	url = {https://www.aasmr.org/jsms/Vol14/No.2/Vol.14.No.2.22.pdf},
	doi = {10.33168/JSMS.2024.0222},
	shorttitle = {Security and Privacy Policy Assessment in Mobile Health Applications},
	abstract = {Currently, the availability of mobile health ({mHealth}) applications is growing, implying the development and effectiveness of healthcare facilities. However, the sensitive medical information potentially intrudes into the privacy and security of users which has not been acknowledged by the user. The lack of guidance regarding privacy policy assessment causes concern with the development of privacy policy requirements based on privacy and security dimensions. This study objectives to identify the requirements of the privacy policy in {mHealth} applications. A narrative review has been conducted using keywords to find related open-source literature published from 2015 to 2022 from Science Direct, {PMC}, and {PubMed} databases to identify the privacy and security assessments based on the perspective of {mHealth} App research. A total of 17 articles were reviewed using the keywords “privacy policy” {AND} “privacy” {AND} “security” {AND} “mobile health”. Three major requirements were found related to privacy and security frameworks namely consistency and transparency, data management and processing, and interconnected-data arrangement. Consistency and transparency involve clear processes, data types, legal safeguards, access provisions, data sharing transparency, and data quality maintenance. Data management and processing require disclosure mechanisms, robust technical security measures, and protocols for vulnerable users. Lastly, an interconnected data arrangement should include data arrangement identification, data sharing policies, and data interconnection procedures.},
	number = {2},
	journaltitle = {Journal of System and Management Sciences},
	shortjournal = {{JSMS}},
	author = {Hakiem, Nashrul and Afrizal, Sandra Hakiem and Setiadi, Yudi and Albab, Hadid Syaifullah and Riasetiawan, Mardhani and Zulhuda, Sonny},
	urldate = {2025-02-19},
	date = {2024-01-29},
	langid = {english},
	file = {PDF:C\:\\Users\\devam\\Zotero\\storage\\ZB7SRTTF\\2024 - Security and Privacy Policy Assessment in Mobile Health Applications A Literature Review.pdf:application/pdf},
}
